# Prompt-Engineering-Benchmark-Suite
This repo contains a set of evaluation data sets for NLP tasks. It can be used to evaluate prompt engineering techniques on the following use case categories: text generation, commonsense reasoning, arithmetic reasoning, reading comprehension, translation, classification, and code generation. 
